{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5ltjY69oHva-"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import ntpath\n",
        "import random\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as npimg\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imgaug import augmenters  as iaa\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, EarlyStopping\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, LSTM, Reshape, Input, Concatenate, ZeroPadding2D, GlobalMaxPool2D, BatchNormalization, Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4i9hsWuKgBE"
      },
      "source": [
        "挂载谷歌硬盘，读取并导入数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWhW9e_lJd8e",
        "outputId": "dd11b4d7-0069-4afe-8401-b02e39911b49"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'E:/training_data_5.pkl'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-5-deccc794befc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpickle_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'E:/training_data_4.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtraining_data_4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpickle_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'E:/training_data_5.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mtraining_data_5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mpickle_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'E:/training_data_6.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:/training_data_5.pkl'"
          ]
        }
      ],
      "source": [
        "\n",
        "pickle_file = open('E:/training_data_1.pkl', 'rb')\n",
        "training_data_1 = np.asarray(pickle.load(pickle_file))\n",
        "pickle_file = open('E:/training_data_2.pkl', 'rb')\n",
        "training_data_2 = np.asarray(pickle.load(pickle_file))\n",
        "pickle_file = open('E:/training_data_3.pkl', 'rb')\n",
        "training_data_3 = np.asarray(pickle.load(pickle_file))\n",
        "pickle_file = open('E:/training_data_4.pkl', 'rb')\n",
        "training_data_4 = np.asarray(pickle.load(pickle_file))\n",
        "pickle_file = open('E:/training_data_5.pkl', 'rb')\n",
        "training_data_5 = np.asarray(pickle.load(pickle_file))\n",
        "pickle_file = open('E:/training_data_6.pkl', 'rb')\n",
        "training_data_6 = np.asarray(pickle.load(pickle_file))\n",
        "pickle_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhR6uqCtfNxg",
        "outputId": "d0f9cea5-8a80-43e1-8230-25d0ead864da"
      },
      "outputs": [],
      "source": [
        "training_data = np.row_stack((training_data_1, training_data_2, training_data_3, training_data_4, training_data_5, training_data_6))\n",
        "del training_data_1, training_data_2, training_data_3, training_data_4, training_data_5, training_data_6 # clean up memory\n",
        "\n",
        "training_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0znsPeGEfjP"
      },
      "outputs": [],
      "source": [
        "for data in training_data:\n",
        "  data[0] = cv2.cvtColor(data[0], cv2.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfN_dsDiD1e8"
      },
      "source": [
        "从数据集中随机抽取一张图并查看相应的键盘输入。可以看到，输入由油门和转向两部分组成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "onZVyeYxCdki",
        "outputId": "6a8f3248-03d4-40f8-ae9d-29aae617a74d"
      },
      "outputs": [],
      "source": [
        "def show_img(index):\n",
        "  plt.title('Sample Image, key = '+ str(training_data[index][1]))\n",
        "  plt.imshow(training_data[index][0])\n",
        "  plt.show()\n",
        "\n",
        "index = np.random.randint(0,len(training_data))\n",
        "show_img(index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZmediENKfiS"
      },
      "source": [
        "分别绘制油门和转向的柱状图。可以看到，油门的值聚集在1，转向的值聚集在0。这是符合常理的，因为开车时大部分时间都在踩油门沿道路直线行驶。不过，如果不处理数据直接训练，训练出的模型会在绝大部分时候选择踩油门直行。因此，必须删除部分踩油门直行的数据，防止造成偏差。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "7CYbHXeWG4d2",
        "outputId": "0f373b78-cf6c-4f8f-dbef-1309959906c8"
      },
      "outputs": [],
      "source": [
        "throttle = [a[1][0] for a in training_data]\n",
        "steering = [a[1][1] for a in training_data]\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axs[0].hist(throttle,3)\n",
        "axs[0].set_title('Throttle')\n",
        "axs[1].hist(steering,3)\n",
        "axs[1].set_title('Steering')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "LG5wIcdUQe9y",
        "outputId": "cdf51936-3034-420a-c8d1-89efdaa338ad"
      },
      "outputs": [],
      "source": [
        "drop_percent = 0.8\n",
        "\n",
        "new = []\n",
        "for data in training_data:\n",
        "  if data[1][0]==1 and data[1][1]==0:\n",
        "    if np.random.randint(1,11)/10>=drop_percent:\n",
        "      new.append(data)\n",
        "  else:\n",
        "    new.append(data)\n",
        "\n",
        "\n",
        "throttle = [a[1][0] for a in new]\n",
        "steering = [a[1][1] for a in new]\n",
        "\n",
        "training_data = np.asarray(new)\n",
        "del new\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axs[0].hist(throttle,3)\n",
        "axs[0].set_title('Throttle')\n",
        "axs[1].hist(steering,3)\n",
        "axs[1].set_title('Steering')\n",
        "\n",
        "del throttle, steering, pickle_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF0OgiOEMQ0n"
      },
      "source": [
        "除了删除部分踩油门直行的数据，还可以通过镜像图片，调整亮度等方式人为地多制造一些转弯数据。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "g4LzQA7oMqfU",
        "outputId": "478780ad-5b19-4ce7-b128-53e6e0302f30"
      },
      "outputs": [],
      "source": [
        "def img_flip(input, percent):\n",
        "  output = input  # make a copy\n",
        "  for data in input:\n",
        "    img, key = data\n",
        "    if key[1]!=0 and np.random.randint(1,11)/10<=percent:   # if has steerling control\n",
        "      img_flipped = cv2.flip(img,1)  # flip the img\n",
        "      key_reversed = [key[0], -key[1]] # reverse the steering input\n",
        "      output = np.row_stack((output,[img_flipped,key_reversed]))\n",
        "\n",
        "  return output\n",
        "\n",
        "def img__brightness(input, percent):\n",
        "  output = input  # make a copy\n",
        "  for data in input:\n",
        "    if np.random.randint(1,11)/10<=percent:\n",
        "      img, key = data\n",
        "      brightness = iaa.Multiply((0.7, 1.5))\n",
        "      img = brightness.augment_image(img)\n",
        "      output = np.row_stack((output,[img,key]))\n",
        "\n",
        "  return output\n",
        "\n",
        "img = training_data[np.random.randint(0,len(training_data))][0]\n",
        "img_1 = cv2.flip(img,1)\n",
        "img_2 = iaa.Multiply((0.2, 1.2)).augment_image(img)\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
        "axs[0].imshow(img)\n",
        "axs[0].set_title('Original')\n",
        "axs[1].imshow(img_1)\n",
        "axs[1].set_title('Flipped')\n",
        "axs[2].imshow(img_2)\n",
        "axs[2].set_title('Brightness')\n",
        "\n",
        "\n",
        "training_data = img_flip(training_data,0.9)\n",
        "training_data = img__brightness(training_data,0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lc4kAs5-K0b6"
      },
      "outputs": [],
      "source": [
        "def key_to_class(key_data):\n",
        "  class_list = np.asarray([[0,1],[0,-1],[0,0],[1,1],[1,-1],[1,0],[-1,1],[-1,-1],[-1,0]])\n",
        "\n",
        "  out = []\n",
        "  for data in key_data:\n",
        "    out.append(np.where(np.all(class_list==data,axis=1)))\n",
        "  \n",
        "  return np.asarray(out).reshape(key_data.shape[0],1)\n",
        "\n",
        "\n",
        "X = [i[0] for i in training_data]\n",
        "t = [i[1] for i in training_data]\n",
        "\n",
        "\n",
        "t = key_to_class(np.array(t))\n",
        "\n",
        "\n",
        "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.2)\n",
        "\n",
        "del X,t\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "X_train = np.array(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mwgs86rakIqT"
      },
      "outputs": [],
      "source": [
        "del training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAtUAbKmHwqi",
        "outputId": "1315f975-e6bf-4919-a71c-9d06e20b52ba"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "\n",
        "  layers.Rescaling(1./255, input_shape=(150, 350, 1)),\n",
        "\n",
        "\n",
        "  layers.Conv2D(24,kernel_size=(3,3), strides=(2,2),padding='same',activation='relu'),\n",
        "\n",
        "\n",
        "  layers.Conv2D(48,kernel_size=(5,5), strides=(2,2),padding='same',activation='relu'),\n",
        "\n",
        "  \n",
        "\n",
        "  layers.Conv2D(64,kernel_size=(3,3), strides=(2,2),padding='same',activation='relu'),\n",
        "\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "  layers.Normalization(),\n",
        "  #1st Dense Layer\n",
        "  layers.Flatten(),\n",
        "\n",
        "  #2nd Dense Layer\n",
        "  layers.Dense(100, activation='relu'),#500\n",
        "  layers.Dropout(0.3),\n",
        "\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  layers.Dropout(0.3),\n",
        "  #output\n",
        "  layers.Dense(9, activation='softmax')\n",
        "\n",
        "\n",
        "  #layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.0001)),\n",
        "\n",
        "])\n",
        "  \n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "print (model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPNezdCupjkK",
        "outputId": "7e52bebe-d9c9-4095-a439-bb259c7ab350"
      },
      "outputs": [],
      "source": [
        "epochs=100\n",
        "early_stopping_callback = EarlyStopping(monitor='val_sparse_categorical_accuracy', patience=5, verbose=1)\n",
        "\n",
        "history = model.fit(X_train,t_train,            \n",
        "  batch_size=128,epochs=epochs, callbacks=early_stopping_callback,\n",
        "  validation_data=(X_test,t_test),validation_freq=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-40_2K6taed"
      },
      "outputs": [],
      "source": [
        "acc = history.history['sparse_categorical_accuracy']\n",
        "val_acc = history.history['val_sparse_categorical_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(acc,label='Training acc')\n",
        "plt.plot(val_acc,label='val acc')\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(loss,label='Training loss')\n",
        "plt.plot(val_loss,label='val loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lz6BBG9TuwFx"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/ETS2AD/model_6.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7bktiy2dIYh"
      },
      "outputs": [],
      "source": [
        "a=[]\n",
        "for i in range(30):\n",
        "\n",
        "  a.append(np.argmax(model.predict(X_test[i].reshape((-1,150, 350)))))\n",
        "  \n",
        "print(a)\n",
        "print(t_test[0:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42VM_eBt6Amu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ETS2AD_train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
